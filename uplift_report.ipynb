{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/remerge/uplift-report/blob/remove-invalid-users-low-memory/uplift_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5mOAgeTNy0-o"
   },
   "source": [
    "# remerge uplift report\n",
    "\n",
    "This notebook allows you to validate remerge provided uplift reporting numbers. To do so it downloads and analyses exported campaign and event data from S3. The campaign data contains all users that remerge marked to be part of an uplift test, the A/B group assignment, the timestamp of marking, conversion events (click, app open or similar) and their cost. The event data reflects the app event stream and includes events, their timestamp and revenue (if any). We calculate the incremental revenue and the iROAS in line with the [remerge whitepaper](https://drive.google.com/file/d/1PTJ93Cpjw1BeiVns8dTcs2zDDWmmjpdc/view). \n",
    "\n",
    "**Hint**: This notebook can be run in any Jupyter instance with enough space/memory, as a [Google Colab notebook](#Google-Colab-version) or as a standalone Python script. If you are using a copy of this notebook running on Colab or locally you can find the original template on [GitHub: remerge/uplift-report](https://github.com/remerge/uplift-report/blob/master/uplift_report_per_campaign.ipynb)\n",
    "\n",
    "### Notebook configuration\n",
    "\n",
    "For this notebook to work properly several variables in the [Configuration](#Configuration) section need to be be set: `customer`, `audience`, `\n",
    "revenue_event`, `dates` and the AWS credentials. All of these will be provided by your remerge account manager. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xxhash\n",
    "!pip install pandas==0.24.0\n",
    "!pip install scipy\n",
    "!pip install s3fs\n",
    "!pip install google.colab\n",
    "!pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OYbsRBPTaCZW"
   },
   "source": [
    "## Google Colab support\n",
    "\n",
    "This notebook can be run inside Google Colab. Due to size limitations it cointains several optimizations like removing unused fields from the input files and caching files. Furthermore it installs missing dependencies and restarts the kernel. **If pandas was upgraded the kernel needs to be restarted once per fresh instance. Just run the cell again after restart** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QoJAOpL0aEIT"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    import google.colab\n",
    "\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    !pip install pyarrow\n",
    "    !pip install xxhash\n",
    "    !pip install partd\n",
    "    \n",
    "    import pandas as pdt\n",
    "    if pdt.__version__ < '0.23.4':\n",
    "        # upgrading pandas requires a restart of the kernel\n",
    "        # (we need an up to date pandas because we write to S3 for caching)\n",
    "        # we kill it and let it auto restart (only needed once per fresh instance)\n",
    "        !pip install pandas==0.23.4\n",
    "        \n",
    "        import os\n",
    "        os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kyYz6TCny0-q"
   },
   "source": [
    "## Import needed packages\n",
    "\n",
    "This notebook/script needs pandas and scipy for analysis and boto to access data store on S3.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWizAQT3y0-r"
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xxhash\n",
    "import re\n",
    "import os\n",
    "import gzip\n",
    "import scipy\n",
    "import scipy.stats\n",
    "import s3fs\n",
    "from google.colab import files\n",
    "from IPython.display import display  # so we can run this as script as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(helpers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Novl387nrno"
   },
   "source": [
    "## Version\n",
    "Version of the analysis script corresponding to the methodology version in the whitepaper (Major + Minor version represent the whitepaper version, revision represents changes and fixes of the uplift report script)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U2vm5Z9UoHe6"
   },
   "outputs": [],
   "source": [
    "display(helpers.VERSION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8u6Q76fCy0-u"
   },
   "source": [
    "## Configuration\n",
    "\n",
    "Set the customer name, audience and access credentials for the S3 bucket and path. Furthermore the event for which we want to evaluate the uplift needs to be set `revenue_event`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wFgBi4jvsVTn"
   },
   "outputs": [],
   "source": [
    "# configure path and revenue event \n",
    "customer = ''\n",
    "audiences = ['']\n",
    "revenue_event = 'purchase'\n",
    "\n",
    "# date range for the report\n",
    "dates = pd.date_range(start='2019-01-01',end='2019-01-01')\n",
    "\n",
    "# AWS credentials\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"] = ''\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = ''\n",
    "\n",
    "# Configure the reporting output: \n",
    "\n",
    "# named groups that aggregate several campaigns\n",
    "groups = {}\n",
    "\n",
    "# show uplift results per campaign:\n",
    "per_campaign_results = False\n",
    "\n",
    "# base statistical calculations on unique converters instead of conversions\n",
    "use_converters_for_significance = False\n",
    "\n",
    "# enable deduplication heuristic for appsflyer\n",
    "use_deduplication = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XnJeThPiSye"
   },
   "source": [
    "## Data loading helpers\n",
    "Define a few helper functions to load and cache data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eSixTLyiy0_A"
   },
   "source": [
    "## Load CSV data from S3\n",
    "\n",
    "Load mark, spend and event data from S3. \n",
    "\n",
    "### IMPORTANT\n",
    "\n",
    "**The event data is usually quite large (several GB) so this operation might take several minutes or hours to complete, depending on the size and connection.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PjWaWZS-y0_B"
   },
   "outputs": [],
   "source": [
    "bid_columns = ['ts', 'user_id', 'ab_test_group', 'campaign_id','cost_eur','event_type']\n",
    "bids_df = pd.concat([helpers.read_csv(customer, audience, 'marks_and_spend', date, columns=bid_columns) for audience in audiences for date in dates],\n",
    "                    ignore_index=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFg_-_EW5TR1"
   },
   "outputs": [],
   "source": [
    "attribution_columns = ['ts', 'user_id', 'partner_event', 'revenue_eur', 'ab_test_group']\n",
    "attributions_df = pd.concat(\n",
    "    [helpers.read_csv(customer, audience, 'attributions', date, attribution_columns, revenue_event, helpers.extract_revenue_events ) for audience in audiences for date in dates],\n",
    "    ignore_index=True, verify_integrity=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ec_qFUaVy0_I"
   },
   "source": [
    "Print some statistics of the loaded data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "N0Ih6SSuy0_J"
   },
   "outputs": [],
   "source": [
    "bids_df.info(memory_usage='deep')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EoU_cW07y0_M"
   },
   "outputs": [],
   "source": [
    "attributions_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deduplication for appsflyer\n",
    "AppsFlyer sends some events twice - we want to remove the duplicates before the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_deduplication:\n",
    "  attributions_df = drop_duplicates_in_attributions(attributions_df, pd.Timedelta('1 minute'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tKdBRvkxL8Aa"
   },
   "source": [
    "### Calculate and display uplift report for the data set as a whole\n",
    "\n",
    "This takes the whole data set and calculates uplift KPIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SjX4uu6tTpK2"
   },
   "outputs": [],
   "source": [
    "report = helpers.uplift_report(bids_df, attributions_df, groups, per_campaign_results, use_converters_for_significance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SdFSmL3u8Pe4"
   },
   "source": [
    "## Uplift Results\n",
    "\n",
    "You can configure the ouput by using variables in the 'Configuration' section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GWQXKYXB8YO2"
   },
   "outputs": [],
   "source": [
    "# set formatting options\n",
    "pd.set_option('display.float_format', '{:.5f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S2UZOvmlaXqO"
   },
   "outputs": [],
   "source": [
    "display(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6VA_k2BobaZS"
   },
   "source": [
    "### CSV Export - combined reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "892WWgnposwy"
   },
   "outputs": [],
   "source": [
    "def export_csv(df, file_name):\n",
    "    df.to_csv(file_name) \n",
    "    files.download(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-T6quwwbObO"
   },
   "outputs": [],
   "source": [
    "start = dates[0]\n",
    "end = dates[-1]\n",
    "export_csv(report),'{}_{}-{}.csv'.format(customer, start, end))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "uplift_report.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:eugen_python_37]",
   "language": "python",
   "name": "conda-env-eugen_python_37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
